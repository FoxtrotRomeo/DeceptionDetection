{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from ztime import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the .csv files in merged_openface_out as dataframes in a dictionary\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# get the current directory\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)\n",
    "# get the path to the directory with the csv files\n",
    "path = path + '/merged_opensmile_out'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# create an empty dictionary to store the dataframes\n",
    "data = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data[name] = df\n",
    "\n",
    "# get the path to the directory with the csv files\n",
    "path = os.getcwd()\n",
    "\n",
    "path = path + '/opensmile_out_A'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "print(all_files)\n",
    "# create an empty dictionary to store the dataframes\n",
    "data_A = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data_A[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of missing values in data and in data_A\n",
    "missing_values = {}\n",
    "for key in data.keys():\n",
    "    missing_values[key] = data[key].isnull().sum().sum()\n",
    "missing_values_A = {}\n",
    "for key in data_A.keys():\n",
    "    missing_values_A[key] = data_A[key].isnull().sum().sum()\n",
    "\n",
    "print(missing_values)\n",
    "print(missing_values_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the full_dataset.csv file into a dataframe. Keep only the 'Dyad Number' and 'Truth/Lie' columns\n",
    "full_dataset = pd.read_csv('full_dataset.csv', usecols=['Dyad Number', 'Truth/Lie'])\n",
    "# delete the duplicates in the full_dataset dataframe based on the 'Dyad Number' column\n",
    "full_dataset = full_dataset.drop_duplicates(subset='Dyad Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to transform the dataframes in a dictionary into a single 3d numpy array, structured as (n_samples, n_features, n_timepoints).\n",
    "# Use the keys of the dictionary, as integers, from the smallest to the largest, as the first dimension of the numpy array.\n",
    "#Use the columns of the dataframes as the second dimension of the numpy array.\n",
    "# Use the rows of the dataframes as the third dimension of the numpy array.\n",
    "\n",
    "def dict_to_array(data):\n",
    "    # get the keys of the dictionary\n",
    "    keys = list(data.keys())\n",
    "    # transform the keys into integers\n",
    "    keys = [int(key) for key in keys]\n",
    "    # sort the keys\n",
    "    keys.sort()\n",
    "    # transform the keys back into strings\n",
    "    keys = [str(key) for key in keys]\n",
    "    # print the keys\n",
    "    print(keys)\n",
    "    # get the number of keys\n",
    "    n_keys = len(keys)\n",
    "    # get the number of columns\n",
    "    n_columns = data[keys[0]].shape[1]\n",
    "    # get the number of rows\n",
    "    n_rows = data[keys[0]].shape[0]\n",
    "    # create an empty numpy array\n",
    "    array = np.zeros((n_keys, n_columns, n_rows))\n",
    "    # loop through the keys\n",
    "    for i in range(n_keys):\n",
    "        # get the key\n",
    "        key = keys[i]\n",
    "        # get the dataframe\n",
    "        df = data[key]\n",
    "        # get the values of the dataframe\n",
    "        values = df.values\n",
    "        # store the values in the numpy array\n",
    "        array[i, :, :] = values.T\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataframes in the dictionary into a single 3d numpy array\n",
    "X = dict_to_array(data)\n",
    "\n",
    "X_A = dict_to_array(data_A)\n",
    "\n",
    "# create a label array, there 'Lie' is 0 and 'Truth' is 1\n",
    "y = full_dataset['Truth/Lie'].values\n",
    "y = np.where(y == 'Lie', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to perform the training using leave one out cross validation and to create the confusion matrix and the classification report\n",
    "def train_one_out(X, y):\n",
    "    # create a leave one out cross validation object\n",
    "    loo = LeaveOneOut()\n",
    "    # create an empty list to store the predictions\n",
    "    predictions = []\n",
    "    # loop through the training and test sets\n",
    "    for i, (train_index, test_index) in enumerate(loo.split(X)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}\")\n",
    "        print(f\"  Test:  index={test_index}\")\n",
    "        \n",
    "        pred, time = helper.simpleTrial(X_train=X[train_index], y_train=y[train_index], X_test=X[test_index], y_test=y[test_index])\n",
    "\n",
    "        # store the prediction\n",
    "        predictions.append(pred)\n",
    "    # create the confusion matrix\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    # create the classification report\n",
    "    cr = classification_report(y, predictions)\n",
    "    return cm, cr, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_Z, cr_Z, predictions_Z = train_one_out(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_Z_A, cr_Z_A, predictions_Z_A = train_one_out(X_A, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to store the results\n",
    "\n",
    "with open('results_Z.txt', 'a') as f:\n",
    "    f.write('Z time on merged_opensmile_out\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_Z))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_Z)\n",
    "    f.write('\\n')\n",
    "    f.write('Z time on opensmile_out_A\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_Z_A))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_Z_A)\n",
    "    f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
