{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sktime.classification.interval_based import CanonicalIntervalForest\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the .csv files in merged_openface_out as dataframes in a dictionary\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# get the current directory\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)\n",
    "# get the path to the directory with the csv files\n",
    "path = path + '/merged_openface_out'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# create an empty dictionary to store the dataframes\n",
    "data = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data[name] = df\n",
    "\n",
    "# get the path to the directory with the csv files\n",
    "path = os.getcwd()\n",
    "\n",
    "path = path + '/openface_out_A'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "print(all_files)\n",
    "# create an empty dictionary to store the dataframes\n",
    "data_A = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data_A[name] = df\n",
    "\n",
    "# get the current directory\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)\n",
    "# get the path to the directory with the csv files\n",
    "path = path + '/merged_opensmile_out'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# create an empty dictionary to store the dataframes\n",
    "data_voice = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data_voice[name] = df\n",
    "\n",
    "# get the current directory\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)\n",
    "# get the path to the directory with the csv files\n",
    "path = path + '/opensmile_out_A'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# create an empty dictionary to store the dataframes\n",
    "data_voice_A = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data_voice_A[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the full_dataset.csv file into a dataframe. Keep only the 'Dyad Number' and 'Truth/Lie' columns\n",
    "full_dataset = pd.read_csv('full_dataset.csv', usecols=['Dyad Number', 'Truth/Lie'])\n",
    "# delete the duplicates in the full_dataset dataframe based on the 'Dyad Number' column\n",
    "full_dataset = full_dataset.drop_duplicates(subset='Dyad Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to transform the dataframes in a dictionary into a single 3d numpy array, structured as (n_samples, n_features, n_timepoints).\n",
    "# Use the keys of the dictionary, as integers, from the smallest to the largest, as the first dimension of the numpy array.\n",
    "#Use the columns of the dataframes as the second dimension of the numpy array.\n",
    "# Use the rows of the dataframes as the third dimension of the numpy array.\n",
    "\n",
    "def dict_to_array(data):\n",
    "    # get the keys of the dictionary\n",
    "    keys = list(data.keys())\n",
    "    # transform the keys into integers\n",
    "    keys = [int(key) for key in keys]\n",
    "    # sort the keys\n",
    "    keys.sort()\n",
    "    # transform the keys back into strings\n",
    "    keys = [str(key) for key in keys]\n",
    "    # print the keys\n",
    "    print(keys)\n",
    "    # get the number of keys\n",
    "    n_keys = len(keys)\n",
    "    # get the number of columns\n",
    "    n_columns = data[keys[0]].shape[1]\n",
    "    # get the number of rows\n",
    "    n_rows = data[keys[0]].shape[0]\n",
    "    # create an empty numpy array\n",
    "    array = np.zeros((n_keys, n_columns, n_rows))\n",
    "    # loop through the keys\n",
    "    for i in range(n_keys):\n",
    "        # get the key\n",
    "        key = keys[i]\n",
    "        # get the dataframe\n",
    "        df = data[key]\n",
    "        # get the values of the dataframe\n",
    "        values = df.values\n",
    "        # store the values in the numpy array\n",
    "        array[i, :, :] = values.T\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataframes in the dictionary into a single 3d numpy array\n",
    "X = dict_to_array(data)\n",
    "\n",
    "X_A = dict_to_array(data_A)\n",
    "\n",
    "X_Voice = dict_to_array(data_voice)\n",
    "\n",
    "X_Voice_A = dict_to_array(data_voice_A)\n",
    "\n",
    "# create a label array, there 'Lie' is 0 and 'Truth' is 1\n",
    "y = full_dataset['Truth/Lie'].values\n",
    "y = np.where(y == 'Lie', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a rocket model\n",
    "rocket = RocketClassifier(num_kernels=1000, random_state=47, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to perform the training using leave one out cross validation and to create the confusion matrix and the classification report\n",
    "def train_one_out(X, y, model):\n",
    "    # create a leave one out cross validation object\n",
    "    loo = LeaveOneOut()\n",
    "    # create an empty list to store the predictions\n",
    "    predictions = []\n",
    "    # loop through the training and test sets\n",
    "    for i, (train_index, test_index) in enumerate(loo.split(X)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}\")\n",
    "        print(f\"  Test:  index={test_index}\")\n",
    "        # train the cif model\n",
    "        model.fit(X[train_index], y[train_index])\n",
    "        # produce a probability prediction\n",
    "        y_pred_test = model.predict(X[test_index])\n",
    "        # store the prediction\n",
    "        predictions.append(y_pred_test)\n",
    "    print(predictions)\n",
    "    # create the confusion matrix\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    # create the classification report\n",
    "    cr = classification_report(y, predictions)\n",
    "    return cm, cr, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rocket, cr_rocket, predictions_rocket = train_one_out(X, y, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rocket_A, cr_rocket_A, predictions_rocket_A = train_one_out(X_A, y, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rocket_Voice, cr_rocket_Voice, predictions_rocket_Voice = train_one_out(X_Voice, y, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rocket_Voice_A, cr_rocket_Voice_A, predictions_rocket_Voice_A = train_one_out(X_Voice_A, y, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the decision tree classifier from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create a decision tree model\n",
    "dt = DecisionTreeClassifier(max_depth=3, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comp_comp = np.concatenate((predictions_rocket, predictions_rocket_Voice), axis=1)\n",
    "X_A_comp = np.concatenate((predictions_rocket_A, predictions_rocket_Voice), axis=1)\n",
    "X_comp_A = np.concatenate((predictions_rocket, predictions_rocket_Voice_A), axis=1)\n",
    "X_A_A = np.concatenate((predictions_rocket_A, predictions_rocket_Voice_A), axis=1)\n",
    "\n",
    "cm_tree_fv, cr_tree_fv, predictions_tree_fv = train_one_out(X_comp_comp, y, dt)\n",
    "cm_tree_av, cr_tree_av, predictions_tree_av = train_one_out(X_A_comp, y, dt)\n",
    "cm_tree_fa, cr_tree_fa, predictions_tree_fa = train_one_out(X_comp_A, y, dt)\n",
    "cm_tree_aa, cr_tree_aa, predictions_tree_aa = train_one_out(X_A_A, y, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to store the results\n",
    "\n",
    "with open('results_tree_2.txt', 'a') as f:\n",
    "    f.write('Decision Tree on merged_opensmile_out and merged_openface_out\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_tree_fv))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_tree_fv)\n",
    "    f.write('\\n')\n",
    "    f.write('Decision Tree on merged_opensmile_out and openface_out_A\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_tree_av))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_tree_av)\n",
    "    f.write('\\n')\n",
    "    f.write('Decision Tree on opensmile_out_A and merged_openface_out\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_tree_av))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_tree_av)\n",
    "    f.write('\\n')\n",
    "    f.write('Decision Tree on opensmile_out_A and openface_out_A\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_tree_aa))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_tree_aa)\n",
    "    f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
