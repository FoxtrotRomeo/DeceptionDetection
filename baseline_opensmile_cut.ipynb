{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the usual libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sktime.classification.interval_based import CanonicalIntervalForest\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/h20/frru0901/deception_experiment\n",
      "['/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_5.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/17_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/13_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/15_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/19_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/4_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/18_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/21_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/9_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/16_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/5_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/20_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/3_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/17_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/6_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/3_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/14_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/4_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/6_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/10_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/19_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/14_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/20_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/6_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/16_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/11_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/10_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/14_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/3_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_5.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/15_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/22_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/11_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/18_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/21_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/5_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/5_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/8_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/4_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_6.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/22_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/18_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/8_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/10_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/19_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/15_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/1_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_6.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/9_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/7_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/7_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/15_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/21_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/13_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/1_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/5_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/19_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/10_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/22_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/1_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/13_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/20_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/1_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/7_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/17_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/15_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/8_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/9_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/21_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/11_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/17_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/9_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/8_4.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/11_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/19_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/7_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/12_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/3_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/18_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/16_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/14_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/8_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/13_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/18_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/11_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/9_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/16_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/7_0.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/6_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/1_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/22_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/2_2.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/4_1.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/21_3.csv', '/home/h20/frru0901/deception_experiment/opensmile_out_A_cut/3_4.csv']\n"
     ]
    }
   ],
   "source": [
    "# import the .csv files in merged_opensmile_out as dataframes in a dictionary\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# get the current directory\n",
    "path = os.getcwd()\n",
    "\n",
    "print(path)\n",
    "# get the path to the directory with the csv files\n",
    "path = path + '/merged_opensmile_out_cut'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# create an empty dictionary to store the dataframes\n",
    "data = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data[name] = df\n",
    "\n",
    "# get the path to the directory with the csv files\n",
    "path = os.getcwd()\n",
    "\n",
    "path = path + '/opensmile_out_A_cut'\n",
    "# get the list of files in the directory\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "print(all_files)\n",
    "# create an empty dictionary to store the dataframes\n",
    "data_A = {}\n",
    "# loop through the list of files\n",
    "for filename in all_files:\n",
    "    # get the name of the file\n",
    "    name = os.path.basename(filename)\n",
    "    # delete the .csv extension\n",
    "    name = name[:-4]\n",
    "    # read the file into a dataframe\n",
    "    df = pd.read_csv(filename, index_col='Unnamed: 0', header=0)\n",
    "    # drop the columns starting with timestamp\n",
    "    df = df.drop(df.filter(regex='timestamp').columns, axis=1)\n",
    "    # store the dataframe in the dictionary\n",
    "    data_A[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12_5': 0, '17_0': 0, '13_0': 0, '15_2': 0, '19_0': 0, '4_3': 0, '2_3': 0, '18_4': 0, '21_2': 0, '9_4': 0, '16_2': 0, '12_1': 0, '5_0': 0, '20_2': 0, '3_3': 0, '17_1': 0, '6_3': 0, '3_1': 0, '14_0': 0, '4_0': 0, '6_1': 0, '10_0': 0, '19_4': 0, '14_1': 0, '20_1': 0, '6_0': 0, '16_1': 0, '11_4': 0, '10_1': 0, '14_3': 0, '3_2': 0, '2_5': 0, '12_3': 0, '15_0': 0, '22_2': 0, '12_0': 0, '11_3': 0, '18_3': 0, '21_1': 0, '5_1': 0, '5_3': 0, '8_0': 0, '4_2': 0, '2_6': 0, '22_1': 0, '18_2': 0, '8_1': 0, '10_2': 0, '19_1': 0, '15_3': 0, '1_1': 0, '12_6': 0, '2_0': 0, '9_1': 0, '7_3': 0, '7_1': 0, '15_4': 0, '21_0': 0, '13_1': 0, '1_0': 0, '5_2': 0, '19_3': 0, '10_3': 0, '2_1': 0, '22_0': 0, '1_3': 0, '13_2': 0, '20_0': 0, '1_4': 0, '7_4': 0, '17_3': 0, '15_1': 0, '2_4': 0, '8_2': 0, '9_3': 0, '12_4': 0, '21_4': 0, '11_1': 0, '17_2': 0, '9_2': 0, '8_4': 0, '11_0': 0, '19_2': 0, '7_2': 0, '12_2': 0, '3_0': 0, '18_1': 0, '16_3': 0, '14_2': 0, '8_3': 0, '13_3': 0, '18_0': 0, '11_2': 0, '9_0': 0, '16_0': 0, '7_0': 0, '6_2': 0, '1_2': 0, '22_3': 0, '2_2': 0, '4_1': 0, '21_3': 0, '3_4': 0}\n",
      "{'12_5': 0, '17_0': 0, '13_0': 0, '15_2': 0, '19_0': 0, '4_3': 0, '2_3': 0, '18_4': 0, '21_2': 0, '9_4': 0, '16_2': 0, '12_1': 0, '5_0': 0, '20_2': 0, '3_3': 0, '17_1': 0, '6_3': 0, '3_1': 0, '14_0': 0, '4_0': 0, '6_1': 0, '10_0': 0, '19_4': 0, '14_1': 0, '20_1': 0, '6_0': 0, '16_1': 0, '11_4': 0, '10_1': 0, '14_3': 0, '3_2': 0, '2_5': 0, '12_3': 0, '15_0': 0, '22_2': 0, '12_0': 0, '11_3': 0, '18_3': 0, '21_1': 0, '5_1': 0, '5_3': 0, '8_0': 0, '4_2': 0, '2_6': 0, '22_1': 0, '18_2': 0, '8_1': 0, '10_2': 0, '19_1': 0, '15_3': 0, '1_1': 0, '12_6': 0, '2_0': 0, '9_1': 0, '7_3': 0, '7_1': 0, '15_4': 0, '21_0': 0, '13_1': 0, '1_0': 0, '5_2': 0, '19_3': 0, '10_3': 0, '2_1': 0, '22_0': 0, '1_3': 0, '13_2': 0, '20_0': 0, '1_4': 0, '7_4': 0, '17_3': 0, '15_1': 0, '2_4': 0, '8_2': 0, '9_3': 0, '12_4': 0, '21_4': 0, '11_1': 0, '17_2': 0, '9_2': 0, '8_4': 0, '11_0': 0, '19_2': 0, '7_2': 0, '12_2': 0, '3_0': 0, '18_1': 0, '16_3': 0, '14_2': 0, '8_3': 0, '13_3': 0, '18_0': 0, '11_2': 0, '9_0': 0, '16_0': 0, '7_0': 0, '6_2': 0, '1_2': 0, '22_3': 0, '2_2': 0, '4_1': 0, '21_3': 0, '3_4': 0}\n"
     ]
    }
   ],
   "source": [
    "# check the number of missing values in data and in data_A\n",
    "missing_values = {}\n",
    "for key in data.keys():\n",
    "    missing_values[key] = data[key].isnull().sum().sum()\n",
    "missing_values_A = {}\n",
    "for key in data_A.keys():\n",
    "    missing_values_A[key] = data_A[key].isnull().sum().sum()\n",
    "\n",
    "print(missing_values)\n",
    "print(missing_values_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_0', '10_1', '10_2', '10_3', '11_0', '11_1', '11_2', '11_3', '11_4', '12_0', '12_1', '12_2', '12_3', '12_4', '12_5', '12_6', '13_0', '13_1', '13_2', '13_3', '14_0', '14_1', '14_2', '14_3', '15_0', '15_1', '15_2', '15_3', '15_4', '16_0', '16_1', '16_2', '16_3', '17_0', '17_1', '17_2', '17_3', '18_0', '18_1', '18_2', '18_3', '18_4', '19_0', '19_1', '19_2', '19_3', '19_4', '1_0', '1_1', '1_2', '1_3', '1_4', '20_0', '20_1', '20_2', '21_0', '21_1', '21_2', '21_3', '21_4', '22_0', '22_1', '22_2', '22_3', '2_0', '2_1', '2_2', '2_3', '2_4', '2_5', '2_6', '3_0', '3_1', '3_2', '3_3', '3_4', '4_0', '4_1', '4_2', '4_3', '5_0', '5_1', '5_2', '5_3', '6_0', '6_1', '6_2', '6_3', '7_0', '7_1', '7_2', '7_3', '7_4', '8_0', '8_1', '8_2', '8_3', '8_4', '9_0', '9_1', '9_2', '9_3', '9_4']\n",
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "sorted_keys = sorted(list(data.keys()))\n",
    "print(sorted_keys)\n",
    "# create a list of groups, where each group is given by the elements of sorted_keys, except the last two characters\n",
    "groups = list(set([key[:-2] for key in sorted_keys]))\n",
    "print(sorted(groups))\n",
    "\n",
    "group_dict = {}\n",
    "for group in groups:\n",
    "    # create a list of keys for the current group\n",
    "    keys = [key for key in sorted_keys if key[:-2] == group]\n",
    "    # create a list of dataframes for the current group\n",
    "    dfs = [data[key] for key in keys]\n",
    "\n",
    "    # append the list of dataframes to the dictionary\n",
    "    group_dict[group] = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(group_dict['7']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the full_dataset.csv file into a dataframe. Keep only the 'Dyad Number' and 'Truth/Lie' columns\n",
    "full_dataset = pd.read_csv('full_dataset.csv', usecols=['Dyad Number', 'Truth/Lie'])\n",
    "# delete the duplicates in the full_dataset dataframe based on the 'Dyad Number' column\n",
    "full_dataset = full_dataset.drop_duplicates(subset='Dyad Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['1_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to transform the dataframes in a dictionary into a single 3d numpy array, structured as (n_samples, n_features, n_timepoints).\n",
    "# Use the keys of the dictionary, as integers, from the smallest to the largest, as the first dimension of the numpy array.\n",
    "#Use the columns of the dataframes as the second dimension of the numpy array.\n",
    "# Use the rows of the dataframes as the third dimension of the numpy array.\n",
    "\n",
    "def dict_to_array(data):\n",
    "    # get the number of keys\n",
    "    n_keys = len(list(data.keys()))\n",
    "    # get the number of columns\n",
    "    n_columns = data[list(data.keys())[0]].shape[1]\n",
    "    # get the number of rows\n",
    "    n_rows = data[list(data.keys())[0]].shape[0]\n",
    "    # create an empty numpy array\n",
    "    array = np.zeros((n_keys, n_columns, n_rows))\n",
    "    # create an empty list to store the groups from the keys\n",
    "    groups = np.array([])\n",
    "    # loop through the keys\n",
    "    for i in range(n_keys):\n",
    "        # get the key\n",
    "        key = list(data.keys())[i]\n",
    "        # get the group: the key except the last two characters\n",
    "        group = key[:-2]\n",
    "        # append the group to the list\n",
    "        groups = np.append(groups, int(group))\n",
    "        df = data[key]\n",
    "        # get the values of the dataframe\n",
    "        values = df.values\n",
    "        # store the values in the numpy array\n",
    "        array[i, :, :] = values.T\n",
    "    for element in groups:\n",
    "        element = int(element)\n",
    "    return array, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on X\n",
      "working on X_A\n"
     ]
    }
   ],
   "source": [
    "# transform the dataframes in the dictionary into a single 3d numpy array\n",
    "print('working on X')\n",
    "X, groups_X = dict_to_array(data)\n",
    "print('working on X_A')\n",
    "X_A, groups_XA = dict_to_array(data_A)\n",
    "\n",
    "# create a label array, there 'Lie' is 0 and 'Truth' is 1\n",
    "y = full_dataset['Truth/Lie'].values\n",
    "y = np.where(y == 'Lie', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in groups_X:\n",
    "    element = int(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary using the \"Dyad Number\" column of the full_dataset dataframe as keys and the \"Truth/Lie\" column as values, where 'Lie' is 0 and 'Truth' is 1\n",
    "map = full_dataset.set_index('Dyad Number').to_dict()['Truth/Lie']\n",
    "# change each truth value in map to 1 and each lie value to 0\n",
    "for key in map.keys():\n",
    "    map[key] = 1 if map[key] == 'Truth' else 0\n",
    "\n",
    "# create a numpy array mapping each value in groups to the corresponding value in map\n",
    "y = np.array([map[group] for group in groups_X])\n",
    "y_a = np.array([map[group] for group in groups_XA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a canonical interval forest model\n",
    "cif = CanonicalIntervalForest(n_estimators=100, random_state=47, n_jobs=-1)\n",
    "\n",
    "# create a rocket model\n",
    "rocket = RocketClassifier(num_kernels=1000, random_state=47, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to perform the training using leave one out cross validation and to create the confusion matrix and the classification report\n",
    "def train_one_out(X, y, model):\n",
    "    # create a leave one out cross validation object\n",
    "    logo = LeaveOneGroupOut()\n",
    "    # create an empty list to store the predictions\n",
    "    predictions = []\n",
    "    # loop through the training and test sets\n",
    "    for i, (train_index, test_index) in enumerate(logo.split(X, y, groups=groups_X)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        print(f\"  Train: index={train_index}\")\n",
    "        print(f\"  Test:  index={test_index}\")\n",
    "        # train the cif model\n",
    "        model.fit(X[train_index], y[train_index])\n",
    "        # the test set contains multiple samples. Produce a prediction for each sample\n",
    "        for j in range(len(test_index)):\n",
    "            # get the test sample\n",
    "            X_test = X[test_index][j]\n",
    "            # reshape X_test to 1, dimnsion 0, dimension 1\n",
    "            X_test = X_test.reshape(1, X_test.shape[0], X_test.shape[1])\n",
    "            y_pred = model.predict(X_test)\n",
    "            # store the prediction\n",
    "            predictions.append(y_pred)\n",
    "        print(len(predictions))\n",
    "    print('for loop done')\n",
    "    # create the confusion matrix\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    # create the classification report\n",
    "    cr = classification_report(y, predictions)\n",
    "    return cm, cr, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  51  52  53  54\n",
      "  55  56  57  58  60  61  62  63  64  66  67  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  98  99 100 101 102]\n",
      "  Test:  index=[50 59 65 68 97]\n",
      "5\n",
      "Fold 1:\n",
      "  Train: index=[  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  32  33  34  35  36  37\n",
      "  38  39  40  41  42  44  45  46  47  48  49  50  51  53  54  55  56  57\n",
      "  58  59  60  61  62  64  65  66  67  68  69  70  71  73  74  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95\n",
      "  96  97  98 100 101 102]\n",
      "  Test:  index=[ 6 31 43 52 63 72 99]\n",
      "12\n",
      "Fold 2:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101]\n",
      "  Test:  index=[ 14  17  30  85 102]\n",
      "17\n",
      "Fold 3:\n",
      "  Train: index=[  0   1   2   3   4   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 101 102]\n",
      "  Test:  index=[  5  19  42 100]\n",
      "21\n",
      "Fold 4:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[12 39 40 60]\n",
      "25\n",
      "Fold 5:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18\n",
      "  19  21  22  23  24  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  97  98  99 100 101 102]\n",
      "  Test:  index=[16 20 25 96]\n",
      "29\n",
      "Fold 6:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  84  85  86  87  88  89  90  91  92  93\n",
      "  94  96  97  98  99 100 101 102]\n",
      "  Test:  index=[54 55 69 83 95]\n",
      "34\n",
      "Fold 7:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  42  43  44  45  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  74\n",
      "  75  76  77  78  79  81  82  83  84  85  86  87  88  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[41 46 73 80 89]\n",
      "39\n",
      "Fold 8:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  75  76  77  78  80  81  82  83  84  85  86  87  88  89  90  91  92  94\n",
      "  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[ 9 53 74 79 93]\n",
      "44\n",
      "Fold 9:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  22  23  24  25  26  27  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[21 28 47 62]\n",
      "48\n",
      "Fold 10:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  28  29  30  31  32  33  34  35  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  78  79  80  82  83  84  85  86  87  88  89  90  91  93  94\n",
      "  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[27 36 77 81 92]\n",
      "53\n",
      "Fold 11:\n",
      "  Train: index=[  1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  33  34  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  49  50  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  76  77\n",
      "  78  79  80  81  82  83  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102]\n",
      "  Test:  index=[ 0 11 32 35 51 75 84]\n",
      "60\n",
      "Fold 12:\n",
      "  Train: index=[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  59  60  61  62  63  64  65  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[ 2 58 66 90]\n",
      "64\n",
      "Fold 13:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  19  20  21  22  24  25  26  27  28  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[18 23 29 88]\n",
      "68\n",
      "Fold 14:\n",
      "  Train: index=[  0   1   2   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  50  51  52  53  54  55  57\n",
      "  58  59  60  61  62  63  64  65  66  67  68  69  70  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[ 3 33 49 56 71]\n",
      "73\n",
      "Fold 15:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  88  89  90  91  92\n",
      "  93  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[10 26 87 94]\n",
      "77\n",
      "Fold 16:\n",
      "  Train: index=[  0   2   3   4   5   6   7   8   9  10  11  12  13  14  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  71  72  73  74\n",
      "  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[ 1 15 70 78]\n",
      "81\n",
      "Fold 17:\n",
      "  Train: index=[  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  38  39  40  41  42  43  44  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  87  88  89  90  92  93  94\n",
      "  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[ 7 37 45 86 91]\n",
      "86\n",
      "Fold 18:\n",
      "  Train: index=[  0   1   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[ 4 22 48 61 82]\n",
      "91\n",
      "Fold 19:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102]\n",
      "  Test:  index=[13 24 67]\n",
      "94\n",
      "Fold 20:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 102]\n",
      "  Test:  index=[  8  38  57  76 101]\n",
      "99\n",
      "Fold 21:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  35  36\n",
      "  37  38  39  40  41  42  43  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  99 100 101 102]\n",
      "  Test:  index=[34 44 64 98]\n",
      "103\n",
      "for loop done\n"
     ]
    }
   ],
   "source": [
    "cm_rocket, cr_rocket, predictions_rocket = train_one_out(X, y, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cif, cr_cif, predictions_cif = train_one_out(X, y, cif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rocket_A, cr_rocket_A, predictions_rocket_A = train_one_out(X_A, y, rocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cif_A, cr_cif_A, predictions_cif_A = train_one_out(X_A, y, cif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to store the results\n",
    "\n",
    "with open('results.txt', 'a') as f:\n",
    "    f.write('Rocket on merged_opensmile_out_cut\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_rocket))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_rocket)\n",
    "    f.write('\\n')\n",
    "    f.write('Rocket on opensmile_out_A_cut\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_rocket_A))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_rocket_A)\n",
    "    f.write('\\n')\n",
    "    f.write('CIF on merged_opensmile_out_cut\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_cif))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_cif)\n",
    "    f.write('\\n')\n",
    "    f.write('CIF on opensmile_out_A_cut\\n')\n",
    "    f.write('Confusion Matrix:\\n')\n",
    "    f.write(str(cm_cif_A))\n",
    "    f.write('\\n')\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(cr_cif_A)\n",
    "    f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
